{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 使用Xception backbone做 Trnasfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 了解如何使用Transfer Learning\n",
    "  #### 了解Transfer Learning的優點，可以觀察模型收斂速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 可以自行嘗試多種架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 15, 15, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 15, 15, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 15, 15, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 13, 13, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 13, 13, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 13, 13, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 13, 13, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 13, 13, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 13, 13, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 128)    8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 7, 7, 128)    0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 128)    512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 128)    0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 7, 7, 128)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 7, 7, 256)    33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 7, 7, 256)    0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 7, 7, 256)    67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 256)    32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4, 4, 256)    1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4, 4, 256)    0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 4, 4, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 4, 4, 728)    188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 4, 4, 728)    0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 2, 2, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 2, 2, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2, 2, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2, 2, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 2, 2, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 2, 2, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 2, 2, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2, 2, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 2, 2, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 2, 2, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 2, 2, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 2, 2, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 2, 2, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 2, 2, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 2, 2, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 2, 2, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 2, 2, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 2, 2, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 2, 2, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 2, 2, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 2, 2, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 2, 2, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 2, 2, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 2, 2, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 2, 2, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 2, 2, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 2, 2, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 2, 2, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 2, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 2, 2, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 2, 2, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 2, 2, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 1, 1, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 1, 1, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1, 1, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 1, 1, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 1, 1, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 1, 1, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 1, 1, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 1, 1, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 1, 1, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 1, 1, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.layers import Input\n",
    " \n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "#include top 決定要不要加入 fully Connected Layer\n",
    "\n",
    "'''Xception 架構'''\n",
    "model = keras.applications.xception.Xception(include_top=False, weights='imagenet', \n",
    "                                             input_tensor=input_tensor, \n",
    "                                             pooling=None, \n",
    "                                             classes=10)\n",
    "\n",
    "'''Resnet 50 架構'''\n",
    "#model=keras.applications.ResNet50(include_top=False, weights='imagenet',\n",
    "                                    #input_tensor=input_tensor,\n",
    "                                    #pooling=None, classes=10)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加層數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model深度： 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kennykang\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#接上原本的output\n",
    "x = model.output\n",
    "\n",
    "'''可以參考Cifar10實作章節'''\n",
    "#GlobalAveragePooling2D\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x=Dropout(p=0.1)(x)\n",
    "\n",
    "predictions = Dense(units=10,activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "#可以先看看模型深度決定鎖定層數\n",
    "print('Model深度：', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 鎖定特定幾層不要更新權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[100:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備 Cifar 10 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 48s 968us/step - loss: 1.4205 - acc: 0.5004\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 46s 927us/step - loss: 1.0227 - acc: 0.6503\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.9064 - acc: 0.6893\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.8209 - acc: 0.7185\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.7430 - acc: 0.7439\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 46s 925us/step - loss: 0.6707 - acc: 0.7693\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.6064 - acc: 0.7921\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.5503 - acc: 0.8118\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.4921 - acc: 0.8297\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.4479 - acc: 0.8457\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.4073 - acc: 0.8596\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.3756 - acc: 0.8720\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 45s 909us/step - loss: 0.3494 - acc: 0.8799\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 45s 905us/step - loss: 0.3235 - acc: 0.8896\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 45s 905us/step - loss: 0.2992 - acc: 0.8982\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.2807 - acc: 0.9048\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.2651 - acc: 0.9107\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 45s 905us/step - loss: 0.2472 - acc: 0.9156\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.2380 - acc: 0.9197\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.2251 - acc: 0.9241\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 45s 905us/step - loss: 0.2180 - acc: 0.9250\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.2088 - acc: 0.9289\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.2053 - acc: 0.9303\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1980 - acc: 0.9335\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.1919 - acc: 0.9358\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1826 - acc: 0.9389\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1742 - acc: 0.9415\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1729 - acc: 0.9415\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.1606 - acc: 0.9467\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1608 - acc: 0.9450\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.1561 - acc: 0.9480\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.1556 - acc: 0.9483\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.1483 - acc: 0.9510\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1455 - acc: 0.9511\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1435 - acc: 0.9519\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1375 - acc: 0.9541\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1351 - acc: 0.9554\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1350 - acc: 0.9557\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.1255 - acc: 0.9583\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.1241 - acc: 0.9579\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1263 - acc: 0.9582\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 45s 905us/step - loss: 0.1221 - acc: 0.9600\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.1213 - acc: 0.9591\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.1156 - acc: 0.9620\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 45s 909us/step - loss: 0.1171 - acc: 0.9613\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1124 - acc: 0.9636\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 45s 909us/step - loss: 0.1117 - acc: 0.9634\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 45s 905us/step - loss: 0.1057 - acc: 0.9660\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.1132 - acc: 0.9622\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.1063 - acc: 0.9657\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.1019 - acc: 0.9660\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.1033 - acc: 0.9659\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.1062 - acc: 0.9650\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 45s 910us/step - loss: 0.1001 - acc: 0.9683\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.0938 - acc: 0.9687\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 45s 909us/step - loss: 0.0938 - acc: 0.9690\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.0979 - acc: 0.9687\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.0927 - acc: 0.9696\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 46s 913us/step - loss: 0.0906 - acc: 0.9695\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.0925 - acc: 0.9706\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 46s 911us/step - loss: 0.0894 - acc: 0.9706\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.0895 - acc: 0.9719\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 45s 910us/step - loss: 0.0877 - acc: 0.9710\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.0857 - acc: 0.9715\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.0872 - acc: 0.9711\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.0862 - acc: 0.9714\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.0843 - acc: 0.9725\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.0860 - acc: 0.9718\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 46s 911us/step - loss: 0.0815 - acc: 0.9723\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.0792 - acc: 0.9736\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 46s 912us/step - loss: 0.0797 - acc: 0.97471s - loss: 0.\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 45s 904us/step - loss: 0.0810 - acc: 0.9735\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.0799 - acc: 0.9739\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 45s 900us/step - loss: 0.0787 - acc: 0.9737\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 46s 917us/step - loss: 0.0755 - acc: 0.9758\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.0761 - acc: 0.9750\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 46s 922us/step - loss: 0.0736 - acc: 0.9759\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 47s 938us/step - loss: 0.0731 - acc: 0.9759\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 46s 921us/step - loss: 0.0734 - acc: 0.9758\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 45s 905us/step - loss: 0.0677 - acc: 0.9778\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.0719 - acc: 0.9762\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 46s 919us/step - loss: 0.0690 - acc: 0.9776\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 46s 918us/step - loss: 0.0724 - acc: 0.9766\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 45s 902us/step - loss: 0.0731 - acc: 0.9764\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 46s 913us/step - loss: 0.0668 - acc: 0.9782\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 45s 909us/step - loss: 0.0640 - acc: 0.9784\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.0693 - acc: 0.9771\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 45s 909us/step - loss: 0.0658 - acc: 0.9784\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 46s 915us/step - loss: 0.0663 - acc: 0.9778\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 46s 924us/step - loss: 0.0644 - acc: 0.9791\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 45s 909us/step - loss: 0.0669 - acc: 0.9780\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 46s 925us/step - loss: 0.0638 - acc: 0.9785\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 48s 950us/step - loss: 0.0607 - acc: 0.9806\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 46s 929us/step - loss: 0.0635 - acc: 0.9795\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 46s 911us/step - loss: 0.0658 - acc: 0.9793\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 45s 901us/step - loss: 0.0656 - acc: 0.9785\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.0628 - acc: 0.9802\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.0657 - acc: 0.9789\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.0594 - acc: 0.9805\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.0618 - acc: 0.9804\n"
     ]
    }
   ],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history  = model.fit(x_train,y_train,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cc99bb0128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_acc = history.history['acc']\n",
    "train_loss = history.history['loss']\n",
    "\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs,train_acc,'b',label='Train Accuracy')\n",
    "plt.title('Train Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs,train_loss,'b',label='Train Loss')\n",
    "plt.title('Train Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
